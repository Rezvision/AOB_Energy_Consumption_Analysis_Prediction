{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41666 entries, 0 to 41665\n",
      "Data columns (total 34 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   time                               41664 non-null  object \n",
      " 1   Comms and Services                 40812 non-null  float64\n",
      " 2   Car Chargers                       40812 non-null  float64\n",
      " 3   Space Heating                      40812 non-null  float64\n",
      " 4   Hot Water                          40812 non-null  float64\n",
      " 5   Sockets                            40812 non-null  float64\n",
      " 6   Lighting                           40812 non-null  float64\n",
      " 7   total_energy                       41664 non-null  object \n",
      " 8   datepart                           41664 non-null  float64\n",
      " 9   weekend                            41664 non-null  object \n",
      " 10  bank holiday                       41664 non-null  object \n",
      " 11  hour                               41664 non-null  float64\n",
      " 12  day of week                        41664 non-null  float64\n",
      " 13  day of month                       41664 non-null  float64\n",
      " 14  month                              41664 non-null  float64\n",
      " 15  year                               41664 non-null  float64\n",
      " 16  forecast_datadate                  41664 non-null  object \n",
      " 17  forecastperiod                     40766 non-null  object \n",
      " 18  forecast_temperature               40766 non-null  float64\n",
      " 19  forecast_feelslike                 40766 non-null  float64\n",
      " 20  forecast_weathertype               40766 non-null  float64\n",
      " 21  forecast_windspeed                 40766 non-null  float64\n",
      " 22  forecast_uvindex                   40766 non-null  float64\n",
      " 23  forecast_precipitationprobability  40766 non-null  float64\n",
      " 24  forecast_winddirection             40766 non-null  object \n",
      " 25  forecast_visibility                40766 non-null  object \n",
      " 26  forecast_interval                  40766 non-null  object \n",
      " 27  observationperiod                  41664 non-null  object \n",
      " 28  observation_temperature            26020 non-null  float64\n",
      " 29  observation_winddirection          25968 non-null  object \n",
      " 30  observation_windspeed              25968 non-null  float64\n",
      " 31  observation_pressure               25672 non-null  float64\n",
      " 32  observation_dewpoint               26002 non-null  float64\n",
      " 33  observation_humidity               26002 non-null  float64\n",
      "dtypes: float64(23), object(11)\n",
      "memory usage: 10.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mscVRstudent22\\AppData\\Local\\Temp\\ipykernel_24924\\267611544.py:17: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Data.csv\")# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import shap\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame after aggregating to daily data and merging with weather/building data\n",
    "df = pd.read_csv(\"Data.csv\")# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# Get the number of rows and columns \n",
    "# rows = len(df.axes[0]) \n",
    "# cols = len(df.axes[1]) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40131 entries, 112 to 41663\n",
      "Data columns (total 27 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   time                               40131 non-null  object \n",
      " 1   Comms and Services                 40131 non-null  float64\n",
      " 2   Car Chargers                       40131 non-null  float64\n",
      " 3   Space Heating                      40131 non-null  float64\n",
      " 4   Hot Water                          40131 non-null  float64\n",
      " 5   Sockets                            40131 non-null  float64\n",
      " 6   Lighting                           40131 non-null  float64\n",
      " 7   total_energy                       40131 non-null  object \n",
      " 8   datepart                           40131 non-null  float64\n",
      " 9   weekend                            40131 non-null  object \n",
      " 10  bank holiday                       40131 non-null  object \n",
      " 11  hour                               40131 non-null  float64\n",
      " 12  day of week                        40131 non-null  float64\n",
      " 13  day of month                       40131 non-null  float64\n",
      " 14  month                              40131 non-null  float64\n",
      " 15  year                               40131 non-null  float64\n",
      " 16  forecast_datadate                  40131 non-null  object \n",
      " 17  forecastperiod                     40131 non-null  object \n",
      " 18  forecast_temperature               40131 non-null  float64\n",
      " 19  forecast_feelslike                 40131 non-null  float64\n",
      " 20  forecast_weathertype               40131 non-null  float64\n",
      " 21  forecast_windspeed                 40131 non-null  float64\n",
      " 22  forecast_uvindex                   40131 non-null  float64\n",
      " 23  forecast_precipitationprobability  40131 non-null  float64\n",
      " 24  forecast_winddirection             40131 non-null  object \n",
      " 25  forecast_visibility                40131 non-null  object \n",
      " 26  forecast_interval                  40131 non-null  object \n",
      "dtypes: float64(18), object(9)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of columns to drop\n",
    "columns_to_drop = [col for col in df.columns if col.startswith('observation')]\n",
    "\n",
    "# Drop these columns from the DataFrame\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Defining Function for turning features into cyclic \n",
    "# def encode(data, col, max_val):\n",
    "#     data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "#     data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # df['month'] = df.datetime.dt.month\n",
    "# df = encode(df, 'month', 12)\n",
    "# df =  encode(df, 'hour', 24)\n",
    "# # df['day'] = df.datetime.dt.day\n",
    "# # df = encode(df, 'day', 31)\n",
    "# df = encode(df, 'day of week', 7)\n",
    "# df = encode(df, 'day of month', 31)\n",
    "# df['working_hours'] = df['hour'].apply(lambda x: 8 <= x <= 17)\n",
    "# df['bank holiday'] = df['bank holiday'].astype(int)\n",
    "# df['weekend'] = df['weekend'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def periodic_spline_transformer(period, n_splines=None, degree=3):\n",
    "#     if n_splines is None:\n",
    "#         n_splines = period\n",
    "#     n_knots = n_splines + 1  # periodic and include_bias is True\n",
    "#     return SplineTransformer(\n",
    "#         degree=degree,\n",
    "#         n_knots=n_knots,\n",
    "#         knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n",
    "#         extrapolation=\"periodic\",\n",
    "#         include_bias=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # df['month'] = df.datetime.dt.month\n",
    "# df= encode(df, 'month', 12)\n",
    "# df =  encode(df, 'hour', 24)\n",
    "# # df['day'] = df.datetime.dt.day\n",
    "# # df = encode(df, 'day', 31)\n",
    "# df = encode(df, 'day of week', 7)\n",
    "# df = encode(df, 'day of month', 31)\n",
    "# df['working_hours'] = df['hour'].apply(lambda x: 8 <= x <= 17)\n",
    "# df['bank holiday'] = df['bank holiday'].astype(int)\n",
    "# df['weekend'] = df['weekend'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "\n",
    "def periodic_spline_transformer(period, n_splines=None, degree=3):\n",
    "    if n_splines is None:\n",
    "        n_splines = period\n",
    "    n_knots = n_splines + 1  # periodic and include_bias is True\n",
    "    return SplineTransformer(\n",
    "        degree=degree,\n",
    "        n_knots=n_knots,\n",
    "        knots=np.linspace(0, period, n_knots).reshape(n_knots, 1),\n",
    "        extrapolation=\"periodic\",\n",
    "        include_bias=True,\n",
    "    )\n",
    "\n",
    "# Apply Spline Transformation\n",
    "def apply_spline_transformer(df, column, period):\n",
    "    spline_transformer = periodic_spline_transformer(period)\n",
    "    transformed_values = spline_transformer.fit_transform(df[[column]])\n",
    "    \n",
    "    # Create new column names for the transformed features\n",
    "    transformed_cols = [f\"{column}_spline_{i}\" for i in range(transformed_values.shape[1])]\n",
    "    df[transformed_cols] = transformed_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       time  Comms and Services  Car Chargers  Space Heating  \\\n",
      "112  2019-04-05 16:00:00+00            0.590111      0.043272       2.564617   \n",
      "113  2019-04-05 17:00:00+00            0.590689      0.043253       2.639575   \n",
      "115  2019-04-05 19:00:00+00            0.590050      0.043139       1.168772   \n",
      "116  2019-04-05 20:00:00+00            0.589536      0.043031       0.916325   \n",
      "119  2019-04-05 23:00:00+00            0.589953      0.043239       0.953847   \n",
      "\n",
      "     Hot Water   Sockets  Lighting total_energy  datepart  weekend  ...  \\\n",
      "112   0.076094  0.077019  0.756983  4.108097218   43560.0        0  ...   \n",
      "113   0.000000  0.048581  0.208511  3.530608334   43560.0        0  ...   \n",
      "115   0.000000  0.052336  0.151611  2.005908333   43560.0        0  ...   \n",
      "116   0.000000  0.046442  0.151839  1.747172223   43560.0        0  ...   \n",
      "119   0.087725  0.067442  0.173542  1.915747223   43560.0        0  ...   \n",
      "\n",
      "     day of month_spline_22  day of month_spline_23 day of month_spline_24  \\\n",
      "112                     0.0                     0.0                    0.0   \n",
      "113                     0.0                     0.0                    0.0   \n",
      "115                     0.0                     0.0                    0.0   \n",
      "116                     0.0                     0.0                    0.0   \n",
      "119                     0.0                     0.0                    0.0   \n",
      "\n",
      "    day of month_spline_25  day of month_spline_26  day of month_spline_27  \\\n",
      "112                    0.0                     0.0                     0.0   \n",
      "113                    0.0                     0.0                     0.0   \n",
      "115                    0.0                     0.0                     0.0   \n",
      "116                    0.0                     0.0                     0.0   \n",
      "119                    0.0                     0.0                     0.0   \n",
      "\n",
      "     day of month_spline_28  day of month_spline_29  day of month_spline_30  \\\n",
      "112                     0.0                     0.0                     0.0   \n",
      "113                     0.0                     0.0                     0.0   \n",
      "115                     0.0                     0.0                     0.0   \n",
      "116                     0.0                     0.0                     0.0   \n",
      "119                     0.0                     0.0                     0.0   \n",
      "\n",
      "     working_hours  \n",
      "112           True  \n",
      "113           True  \n",
      "115          False  \n",
      "116          False  \n",
      "119          False  \n",
      "\n",
      "[5 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply spline transformation for the temporal features\n",
    "df = apply_spline_transformer(df, 'month', 12)\n",
    "df = apply_spline_transformer(df, 'hour', 24)\n",
    "df = apply_spline_transformer(df, 'day of week', 7)\n",
    "df = apply_spline_transformer(df, 'day of month', 31)\n",
    "\n",
    "# Additional feature engineering\n",
    "df['working_hours'] = df['hour'].apply(lambda x: 8 <= x <= 17)\n",
    "df['bank holiday'] = df['bank holiday'].astype(int)\n",
    "df['weekend'] = df['weekend'].astype(int)\n",
    "\n",
    "# Drop the original columns if no longer needed\n",
    "df.drop(columns=['month', 'hour', 'day of week', 'day of month'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40131 entries, 112 to 41663\n",
      "Data columns (total 98 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   time                               40131 non-null  object \n",
      " 1   Comms and Services                 40131 non-null  float64\n",
      " 2   Car Chargers                       40131 non-null  float64\n",
      " 3   Space Heating                      40131 non-null  float64\n",
      " 4   Hot Water                          40131 non-null  float64\n",
      " 5   Sockets                            40131 non-null  float64\n",
      " 6   Lighting                           40131 non-null  float64\n",
      " 7   total_energy                       40131 non-null  object \n",
      " 8   datepart                           40131 non-null  float64\n",
      " 9   weekend                            40131 non-null  int32  \n",
      " 10  bank holiday                       40131 non-null  int32  \n",
      " 11  year                               40131 non-null  float64\n",
      " 12  forecast_datadate                  40131 non-null  object \n",
      " 13  forecastperiod                     40131 non-null  object \n",
      " 14  forecast_temperature               40131 non-null  float64\n",
      " 15  forecast_feelslike                 40131 non-null  float64\n",
      " 16  forecast_weathertype               40131 non-null  float64\n",
      " 17  forecast_windspeed                 40131 non-null  float64\n",
      " 18  forecast_uvindex                   40131 non-null  float64\n",
      " 19  forecast_precipitationprobability  40131 non-null  float64\n",
      " 20  forecast_winddirection             40131 non-null  object \n",
      " 21  forecast_visibility                40131 non-null  object \n",
      " 22  forecast_interval                  40131 non-null  object \n",
      " 23  month_spline_0                     40131 non-null  float64\n",
      " 24  month_spline_1                     40131 non-null  float64\n",
      " 25  month_spline_2                     40131 non-null  float64\n",
      " 26  month_spline_3                     40131 non-null  float64\n",
      " 27  month_spline_4                     40131 non-null  float64\n",
      " 28  month_spline_5                     40131 non-null  float64\n",
      " 29  month_spline_6                     40131 non-null  float64\n",
      " 30  month_spline_7                     40131 non-null  float64\n",
      " 31  month_spline_8                     40131 non-null  float64\n",
      " 32  month_spline_9                     40131 non-null  float64\n",
      " 33  month_spline_10                    40131 non-null  float64\n",
      " 34  month_spline_11                    40131 non-null  float64\n",
      " 35  hour_spline_0                      40131 non-null  float64\n",
      " 36  hour_spline_1                      40131 non-null  float64\n",
      " 37  hour_spline_2                      40131 non-null  float64\n",
      " 38  hour_spline_3                      40131 non-null  float64\n",
      " 39  hour_spline_4                      40131 non-null  float64\n",
      " 40  hour_spline_5                      40131 non-null  float64\n",
      " 41  hour_spline_6                      40131 non-null  float64\n",
      " 42  hour_spline_7                      40131 non-null  float64\n",
      " 43  hour_spline_8                      40131 non-null  float64\n",
      " 44  hour_spline_9                      40131 non-null  float64\n",
      " 45  hour_spline_10                     40131 non-null  float64\n",
      " 46  hour_spline_11                     40131 non-null  float64\n",
      " 47  hour_spline_12                     40131 non-null  float64\n",
      " 48  hour_spline_13                     40131 non-null  float64\n",
      " 49  hour_spline_14                     40131 non-null  float64\n",
      " 50  hour_spline_15                     40131 non-null  float64\n",
      " 51  hour_spline_16                     40131 non-null  float64\n",
      " 52  hour_spline_17                     40131 non-null  float64\n",
      " 53  hour_spline_18                     40131 non-null  float64\n",
      " 54  hour_spline_19                     40131 non-null  float64\n",
      " 55  hour_spline_20                     40131 non-null  float64\n",
      " 56  hour_spline_21                     40131 non-null  float64\n",
      " 57  hour_spline_22                     40131 non-null  float64\n",
      " 58  hour_spline_23                     40131 non-null  float64\n",
      " 59  day of week_spline_0               40131 non-null  float64\n",
      " 60  day of week_spline_1               40131 non-null  float64\n",
      " 61  day of week_spline_2               40131 non-null  float64\n",
      " 62  day of week_spline_3               40131 non-null  float64\n",
      " 63  day of week_spline_4               40131 non-null  float64\n",
      " 64  day of week_spline_5               40131 non-null  float64\n",
      " 65  day of week_spline_6               40131 non-null  float64\n",
      " 66  day of month_spline_0              40131 non-null  float64\n",
      " 67  day of month_spline_1              40131 non-null  float64\n",
      " 68  day of month_spline_2              40131 non-null  float64\n",
      " 69  day of month_spline_3              40131 non-null  float64\n",
      " 70  day of month_spline_4              40131 non-null  float64\n",
      " 71  day of month_spline_5              40131 non-null  float64\n",
      " 72  day of month_spline_6              40131 non-null  float64\n",
      " 73  day of month_spline_7              40131 non-null  float64\n",
      " 74  day of month_spline_8              40131 non-null  float64\n",
      " 75  day of month_spline_9              40131 non-null  float64\n",
      " 76  day of month_spline_10             40131 non-null  float64\n",
      " 77  day of month_spline_11             40131 non-null  float64\n",
      " 78  day of month_spline_12             40131 non-null  float64\n",
      " 79  day of month_spline_13             40131 non-null  float64\n",
      " 80  day of month_spline_14             40131 non-null  float64\n",
      " 81  day of month_spline_15             40131 non-null  float64\n",
      " 82  day of month_spline_16             40131 non-null  float64\n",
      " 83  day of month_spline_17             40131 non-null  float64\n",
      " 84  day of month_spline_18             40131 non-null  float64\n",
      " 85  day of month_spline_19             40131 non-null  float64\n",
      " 86  day of month_spline_20             40131 non-null  float64\n",
      " 87  day of month_spline_21             40131 non-null  float64\n",
      " 88  day of month_spline_22             40131 non-null  float64\n",
      " 89  day of month_spline_23             40131 non-null  float64\n",
      " 90  day of month_spline_24             40131 non-null  float64\n",
      " 91  day of month_spline_25             40131 non-null  float64\n",
      " 92  day of month_spline_26             40131 non-null  float64\n",
      " 93  day of month_spline_27             40131 non-null  float64\n",
      " 94  day of month_spline_28             40131 non-null  float64\n",
      " 95  day of month_spline_29             40131 non-null  float64\n",
      " 96  day of month_spline_30             40131 non-null  float64\n",
      " 97  working_hours                      40131 non-null  bool   \n",
      "dtypes: bool(1), float64(88), int32(2), object(7)\n",
      "memory usage: 29.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['weekend','bank holiday']\n",
    "\n",
    "# Convert 0 and 1 to boolean values in specified columns\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(bool)\n",
    "# Sum specified columns to create 'total_aob_energy'\n",
    "df['total_aob_energy'] = df[[ 'Hot Water', 'Sockets', 'Lighting','Comms and Services', 'Space Heating']].sum(axis=1, skipna=True)\n",
    "\n",
    "# Drop the original columns except 'Car Chargers'\n",
    "df.drop(['Comms and Services', 'Space Heating', 'Hot Water', 'Sockets', 'Lighting' ], axis=1, inplace=True)\n",
    "\n",
    "# Now, 'df' contains the new 'total_aob_energy' column and has the specified columns dropped, except 'Car Chargers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40131 entries, 112 to 41663\n",
      "Data columns (total 88 columns):\n",
      " #   Column                             Non-Null Count  Dtype              \n",
      "---  ------                             --------------  -----              \n",
      " 0   time                               40131 non-null  datetime64[ns, UTC]\n",
      " 1   Car Chargers                       40131 non-null  float64            \n",
      " 2   datepart                           40131 non-null  float64            \n",
      " 3   weekend                            40131 non-null  bool               \n",
      " 4   bank holiday                       40131 non-null  bool               \n",
      " 5   year                               40131 non-null  float64            \n",
      " 6   forecast_temperature               40131 non-null  float64            \n",
      " 7   forecast_feelslike                 40131 non-null  float64            \n",
      " 8   forecast_weathertype               40131 non-null  float64            \n",
      " 9   forecast_windspeed                 40131 non-null  float64            \n",
      " 10  forecast_uvindex                   40131 non-null  float64            \n",
      " 11  forecast_precipitationprobability  40131 non-null  float64            \n",
      " 12  month_spline_0                     40131 non-null  float64            \n",
      " 13  month_spline_1                     40131 non-null  float64            \n",
      " 14  month_spline_2                     40131 non-null  float64            \n",
      " 15  month_spline_3                     40131 non-null  float64            \n",
      " 16  month_spline_4                     40131 non-null  float64            \n",
      " 17  month_spline_5                     40131 non-null  float64            \n",
      " 18  month_spline_6                     40131 non-null  float64            \n",
      " 19  month_spline_7                     40131 non-null  float64            \n",
      " 20  month_spline_8                     40131 non-null  float64            \n",
      " 21  month_spline_9                     40131 non-null  float64            \n",
      " 22  month_spline_10                    40131 non-null  float64            \n",
      " 23  month_spline_11                    40131 non-null  float64            \n",
      " 24  hour_spline_0                      40131 non-null  float64            \n",
      " 25  hour_spline_1                      40131 non-null  float64            \n",
      " 26  hour_spline_2                      40131 non-null  float64            \n",
      " 27  hour_spline_3                      40131 non-null  float64            \n",
      " 28  hour_spline_4                      40131 non-null  float64            \n",
      " 29  hour_spline_5                      40131 non-null  float64            \n",
      " 30  hour_spline_6                      40131 non-null  float64            \n",
      " 31  hour_spline_7                      40131 non-null  float64            \n",
      " 32  hour_spline_8                      40131 non-null  float64            \n",
      " 33  hour_spline_9                      40131 non-null  float64            \n",
      " 34  hour_spline_10                     40131 non-null  float64            \n",
      " 35  hour_spline_11                     40131 non-null  float64            \n",
      " 36  hour_spline_12                     40131 non-null  float64            \n",
      " 37  hour_spline_13                     40131 non-null  float64            \n",
      " 38  hour_spline_14                     40131 non-null  float64            \n",
      " 39  hour_spline_15                     40131 non-null  float64            \n",
      " 40  hour_spline_16                     40131 non-null  float64            \n",
      " 41  hour_spline_17                     40131 non-null  float64            \n",
      " 42  hour_spline_18                     40131 non-null  float64            \n",
      " 43  hour_spline_19                     40131 non-null  float64            \n",
      " 44  hour_spline_20                     40131 non-null  float64            \n",
      " 45  hour_spline_21                     40131 non-null  float64            \n",
      " 46  hour_spline_22                     40131 non-null  float64            \n",
      " 47  hour_spline_23                     40131 non-null  float64            \n",
      " 48  day of week_spline_0               40131 non-null  float64            \n",
      " 49  day of week_spline_1               40131 non-null  float64            \n",
      " 50  day of week_spline_2               40131 non-null  float64            \n",
      " 51  day of week_spline_3               40131 non-null  float64            \n",
      " 52  day of week_spline_4               40131 non-null  float64            \n",
      " 53  day of week_spline_5               40131 non-null  float64            \n",
      " 54  day of week_spline_6               40131 non-null  float64            \n",
      " 55  day of month_spline_0              40131 non-null  float64            \n",
      " 56  day of month_spline_1              40131 non-null  float64            \n",
      " 57  day of month_spline_2              40131 non-null  float64            \n",
      " 58  day of month_spline_3              40131 non-null  float64            \n",
      " 59  day of month_spline_4              40131 non-null  float64            \n",
      " 60  day of month_spline_5              40131 non-null  float64            \n",
      " 61  day of month_spline_6              40131 non-null  float64            \n",
      " 62  day of month_spline_7              40131 non-null  float64            \n",
      " 63  day of month_spline_8              40131 non-null  float64            \n",
      " 64  day of month_spline_9              40131 non-null  float64            \n",
      " 65  day of month_spline_10             40131 non-null  float64            \n",
      " 66  day of month_spline_11             40131 non-null  float64            \n",
      " 67  day of month_spline_12             40131 non-null  float64            \n",
      " 68  day of month_spline_13             40131 non-null  float64            \n",
      " 69  day of month_spline_14             40131 non-null  float64            \n",
      " 70  day of month_spline_15             40131 non-null  float64            \n",
      " 71  day of month_spline_16             40131 non-null  float64            \n",
      " 72  day of month_spline_17             40131 non-null  float64            \n",
      " 73  day of month_spline_18             40131 non-null  float64            \n",
      " 74  day of month_spline_19             40131 non-null  float64            \n",
      " 75  day of month_spline_20             40131 non-null  float64            \n",
      " 76  day of month_spline_21             40131 non-null  float64            \n",
      " 77  day of month_spline_22             40131 non-null  float64            \n",
      " 78  day of month_spline_23             40131 non-null  float64            \n",
      " 79  day of month_spline_24             40131 non-null  float64            \n",
      " 80  day of month_spline_25             40131 non-null  float64            \n",
      " 81  day of month_spline_26             40131 non-null  float64            \n",
      " 82  day of month_spline_27             40131 non-null  float64            \n",
      " 83  day of month_spline_28             40131 non-null  float64            \n",
      " 84  day of month_spline_29             40131 non-null  float64            \n",
      " 85  day of month_spline_30             40131 non-null  float64            \n",
      " 86  working_hours                      40131 non-null  bool               \n",
      " 87  total_aob_energy                   40131 non-null  float64            \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), float64(84)\n",
      "memory usage: 26.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.select_dtypes(exclude=['object'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Car chargers', 'Datepart', 'Weekend', 'Bank holiday', 'Year',\n",
      "       'Forecast_temperature', 'Forecast_feelslike', 'Forecast_weathertype',\n",
      "       'Forecast_windspeed', 'Forecast_uvindex',\n",
      "       'Forecast_precipitationprobability', 'Month_spline_0', 'Month_spline_1',\n",
      "       'Month_spline_2', 'Month_spline_3', 'Month_spline_4', 'Month_spline_5',\n",
      "       'Month_spline_6', 'Month_spline_7', 'Month_spline_8', 'Month_spline_9',\n",
      "       'Month_spline_10', 'Month_spline_11', 'Hour_spline_0', 'Hour_spline_1',\n",
      "       'Hour_spline_2', 'Hour_spline_3', 'Hour_spline_4', 'Hour_spline_5',\n",
      "       'Hour_spline_6', 'Hour_spline_7', 'Hour_spline_8', 'Hour_spline_9',\n",
      "       'Hour_spline_10', 'Hour_spline_11', 'Hour_spline_12', 'Hour_spline_13',\n",
      "       'Hour_spline_14', 'Hour_spline_15', 'Hour_spline_16', 'Hour_spline_17',\n",
      "       'Hour_spline_18', 'Hour_spline_19', 'Hour_spline_20', 'Hour_spline_21',\n",
      "       'Hour_spline_22', 'Hour_spline_23', 'Day of week_spline_0',\n",
      "       'Day of week_spline_1', 'Day of week_spline_2', 'Day of week_spline_3',\n",
      "       'Day of week_spline_4', 'Day of week_spline_5', 'Day of week_spline_6',\n",
      "       'Day of month_spline_0', 'Day of month_spline_1',\n",
      "       'Day of month_spline_2', 'Day of month_spline_3',\n",
      "       'Day of month_spline_4', 'Day of month_spline_5',\n",
      "       'Day of month_spline_6', 'Day of month_spline_7',\n",
      "       'Day of month_spline_8', 'Day of month_spline_9',\n",
      "       'Day of month_spline_10', 'Day of month_spline_11',\n",
      "       'Day of month_spline_12', 'Day of month_spline_13',\n",
      "       'Day of month_spline_14', 'Day of month_spline_15',\n",
      "       'Day of month_spline_16', 'Day of month_spline_17',\n",
      "       'Day of month_spline_18', 'Day of month_spline_19',\n",
      "       'Day of month_spline_20', 'Day of month_spline_21',\n",
      "       'Day of month_spline_22', 'Day of month_spline_23',\n",
      "       'Day of month_spline_24', 'Day of month_spline_25',\n",
      "       'Day of month_spline_26', 'Day of month_spline_27',\n",
      "       'Day of month_spline_28', 'Day of month_spline_29',\n",
      "       'Day of month_spline_30', 'Working_hours', 'Total_aob_energy'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40131 entries, 112 to 41663\n",
      "Data columns (total 88 columns):\n",
      " #   Column                             Non-Null Count  Dtype              \n",
      "---  ------                             --------------  -----              \n",
      " 0   Time                               40131 non-null  datetime64[ns, UTC]\n",
      " 1   Car chargers                       40131 non-null  float64            \n",
      " 2   Datepart                           40131 non-null  float64            \n",
      " 3   Weekend                            40131 non-null  bool               \n",
      " 4   Bank holiday                       40131 non-null  bool               \n",
      " 5   Year                               40131 non-null  float64            \n",
      " 6   Forecast_temperature               40131 non-null  float64            \n",
      " 7   Forecast_feelslike                 40131 non-null  float64            \n",
      " 8   Forecast_weathertype               40131 non-null  float64            \n",
      " 9   Forecast_windspeed                 40131 non-null  float64            \n",
      " 10  Forecast_uvindex                   40131 non-null  float64            \n",
      " 11  Forecast_precipitationprobability  40131 non-null  float64            \n",
      " 12  Month_spline_0                     40131 non-null  float64            \n",
      " 13  Month_spline_1                     40131 non-null  float64            \n",
      " 14  Month_spline_2                     40131 non-null  float64            \n",
      " 15  Month_spline_3                     40131 non-null  float64            \n",
      " 16  Month_spline_4                     40131 non-null  float64            \n",
      " 17  Month_spline_5                     40131 non-null  float64            \n",
      " 18  Month_spline_6                     40131 non-null  float64            \n",
      " 19  Month_spline_7                     40131 non-null  float64            \n",
      " 20  Month_spline_8                     40131 non-null  float64            \n",
      " 21  Month_spline_9                     40131 non-null  float64            \n",
      " 22  Month_spline_10                    40131 non-null  float64            \n",
      " 23  Month_spline_11                    40131 non-null  float64            \n",
      " 24  Hour_spline_0                      40131 non-null  float64            \n",
      " 25  Hour_spline_1                      40131 non-null  float64            \n",
      " 26  Hour_spline_2                      40131 non-null  float64            \n",
      " 27  Hour_spline_3                      40131 non-null  float64            \n",
      " 28  Hour_spline_4                      40131 non-null  float64            \n",
      " 29  Hour_spline_5                      40131 non-null  float64            \n",
      " 30  Hour_spline_6                      40131 non-null  float64            \n",
      " 31  Hour_spline_7                      40131 non-null  float64            \n",
      " 32  Hour_spline_8                      40131 non-null  float64            \n",
      " 33  Hour_spline_9                      40131 non-null  float64            \n",
      " 34  Hour_spline_10                     40131 non-null  float64            \n",
      " 35  Hour_spline_11                     40131 non-null  float64            \n",
      " 36  Hour_spline_12                     40131 non-null  float64            \n",
      " 37  Hour_spline_13                     40131 non-null  float64            \n",
      " 38  Hour_spline_14                     40131 non-null  float64            \n",
      " 39  Hour_spline_15                     40131 non-null  float64            \n",
      " 40  Hour_spline_16                     40131 non-null  float64            \n",
      " 41  Hour_spline_17                     40131 non-null  float64            \n",
      " 42  Hour_spline_18                     40131 non-null  float64            \n",
      " 43  Hour_spline_19                     40131 non-null  float64            \n",
      " 44  Hour_spline_20                     40131 non-null  float64            \n",
      " 45  Hour_spline_21                     40131 non-null  float64            \n",
      " 46  Hour_spline_22                     40131 non-null  float64            \n",
      " 47  Hour_spline_23                     40131 non-null  float64            \n",
      " 48  Day of week_spline_0               40131 non-null  float64            \n",
      " 49  Day of week_spline_1               40131 non-null  float64            \n",
      " 50  Day of week_spline_2               40131 non-null  float64            \n",
      " 51  Day of week_spline_3               40131 non-null  float64            \n",
      " 52  Day of week_spline_4               40131 non-null  float64            \n",
      " 53  Day of week_spline_5               40131 non-null  float64            \n",
      " 54  Day of week_spline_6               40131 non-null  float64            \n",
      " 55  Day of month_spline_0              40131 non-null  float64            \n",
      " 56  Day of month_spline_1              40131 non-null  float64            \n",
      " 57  Day of month_spline_2              40131 non-null  float64            \n",
      " 58  Day of month_spline_3              40131 non-null  float64            \n",
      " 59  Day of month_spline_4              40131 non-null  float64            \n",
      " 60  Day of month_spline_5              40131 non-null  float64            \n",
      " 61  Day of month_spline_6              40131 non-null  float64            \n",
      " 62  Day of month_spline_7              40131 non-null  float64            \n",
      " 63  Day of month_spline_8              40131 non-null  float64            \n",
      " 64  Day of month_spline_9              40131 non-null  float64            \n",
      " 65  Day of month_spline_10             40131 non-null  float64            \n",
      " 66  Day of month_spline_11             40131 non-null  float64            \n",
      " 67  Day of month_spline_12             40131 non-null  float64            \n",
      " 68  Day of month_spline_13             40131 non-null  float64            \n",
      " 69  Day of month_spline_14             40131 non-null  float64            \n",
      " 70  Day of month_spline_15             40131 non-null  float64            \n",
      " 71  Day of month_spline_16             40131 non-null  float64            \n",
      " 72  Day of month_spline_17             40131 non-null  float64            \n",
      " 73  Day of month_spline_18             40131 non-null  float64            \n",
      " 74  Day of month_spline_19             40131 non-null  float64            \n",
      " 75  Day of month_spline_20             40131 non-null  float64            \n",
      " 76  Day of month_spline_21             40131 non-null  float64            \n",
      " 77  Day of month_spline_22             40131 non-null  float64            \n",
      " 78  Day of month_spline_23             40131 non-null  float64            \n",
      " 79  Day of month_spline_24             40131 non-null  float64            \n",
      " 80  Day of month_spline_25             40131 non-null  float64            \n",
      " 81  Day of month_spline_26             40131 non-null  float64            \n",
      " 82  Day of month_spline_27             40131 non-null  float64            \n",
      " 83  Day of month_spline_28             40131 non-null  float64            \n",
      " 84  Day of month_spline_29             40131 non-null  float64            \n",
      " 85  Day of month_spline_30             40131 non-null  float64            \n",
      " 86  Working_hours                      40131 non-null  bool               \n",
      " 87  Total_aob_energy                   40131 non-null  float64            \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), float64(84)\n",
      "memory usage: 26.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.columns = [col.capitalize() for col in df.columns]\n",
    "print(df.columns)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Car chargers','Datepart'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = []\n",
    "for col in df.columns:\n",
    "    # Remove \"Forecast_\" if it exists and capitalize the first letter of the remaining string\n",
    "    if col.startswith('Forecast_'):\n",
    "        new_name = col.replace('Forecast_', '')  # Remove 'Forecast_'\n",
    "        new_name = new_name.capitalize()  # Capitalize the first letter\n",
    "    else:\n",
    "        new_name = col  # Keep the original name if it doesn't start with 'Forecast_'\n",
    "    new_columns.append(new_name)\n",
    "\n",
    "# Assign the modified column names back to the DataFrame\n",
    "df.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'date' column as the DataFrame index\n",
    "df.set_index('Time', inplace=True)\n",
    "#removing precovid data\n",
    "df = df[df.index >= \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 25470 entries, 2021-01-01 00:00:00+00:00 to 2023-12-31 23:00:00+00:00\n",
      "Data columns (total 85 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Weekend                   25470 non-null  bool   \n",
      " 1   Bank holiday              25470 non-null  bool   \n",
      " 2   Year                      25470 non-null  float64\n",
      " 3   Temperature               25470 non-null  float64\n",
      " 4   Feelslike                 25470 non-null  float64\n",
      " 5   Weathertype               25470 non-null  float64\n",
      " 6   Windspeed                 25470 non-null  float64\n",
      " 7   Uvindex                   25470 non-null  float64\n",
      " 8   Precipitationprobability  25470 non-null  float64\n",
      " 9   Month_spline_0            25470 non-null  float64\n",
      " 10  Month_spline_1            25470 non-null  float64\n",
      " 11  Month_spline_2            25470 non-null  float64\n",
      " 12  Month_spline_3            25470 non-null  float64\n",
      " 13  Month_spline_4            25470 non-null  float64\n",
      " 14  Month_spline_5            25470 non-null  float64\n",
      " 15  Month_spline_6            25470 non-null  float64\n",
      " 16  Month_spline_7            25470 non-null  float64\n",
      " 17  Month_spline_8            25470 non-null  float64\n",
      " 18  Month_spline_9            25470 non-null  float64\n",
      " 19  Month_spline_10           25470 non-null  float64\n",
      " 20  Month_spline_11           25470 non-null  float64\n",
      " 21  Hour_spline_0             25470 non-null  float64\n",
      " 22  Hour_spline_1             25470 non-null  float64\n",
      " 23  Hour_spline_2             25470 non-null  float64\n",
      " 24  Hour_spline_3             25470 non-null  float64\n",
      " 25  Hour_spline_4             25470 non-null  float64\n",
      " 26  Hour_spline_5             25470 non-null  float64\n",
      " 27  Hour_spline_6             25470 non-null  float64\n",
      " 28  Hour_spline_7             25470 non-null  float64\n",
      " 29  Hour_spline_8             25470 non-null  float64\n",
      " 30  Hour_spline_9             25470 non-null  float64\n",
      " 31  Hour_spline_10            25470 non-null  float64\n",
      " 32  Hour_spline_11            25470 non-null  float64\n",
      " 33  Hour_spline_12            25470 non-null  float64\n",
      " 34  Hour_spline_13            25470 non-null  float64\n",
      " 35  Hour_spline_14            25470 non-null  float64\n",
      " 36  Hour_spline_15            25470 non-null  float64\n",
      " 37  Hour_spline_16            25470 non-null  float64\n",
      " 38  Hour_spline_17            25470 non-null  float64\n",
      " 39  Hour_spline_18            25470 non-null  float64\n",
      " 40  Hour_spline_19            25470 non-null  float64\n",
      " 41  Hour_spline_20            25470 non-null  float64\n",
      " 42  Hour_spline_21            25470 non-null  float64\n",
      " 43  Hour_spline_22            25470 non-null  float64\n",
      " 44  Hour_spline_23            25470 non-null  float64\n",
      " 45  Day of week_spline_0      25470 non-null  float64\n",
      " 46  Day of week_spline_1      25470 non-null  float64\n",
      " 47  Day of week_spline_2      25470 non-null  float64\n",
      " 48  Day of week_spline_3      25470 non-null  float64\n",
      " 49  Day of week_spline_4      25470 non-null  float64\n",
      " 50  Day of week_spline_5      25470 non-null  float64\n",
      " 51  Day of week_spline_6      25470 non-null  float64\n",
      " 52  Day of month_spline_0     25470 non-null  float64\n",
      " 53  Day of month_spline_1     25470 non-null  float64\n",
      " 54  Day of month_spline_2     25470 non-null  float64\n",
      " 55  Day of month_spline_3     25470 non-null  float64\n",
      " 56  Day of month_spline_4     25470 non-null  float64\n",
      " 57  Day of month_spline_5     25470 non-null  float64\n",
      " 58  Day of month_spline_6     25470 non-null  float64\n",
      " 59  Day of month_spline_7     25470 non-null  float64\n",
      " 60  Day of month_spline_8     25470 non-null  float64\n",
      " 61  Day of month_spline_9     25470 non-null  float64\n",
      " 62  Day of month_spline_10    25470 non-null  float64\n",
      " 63  Day of month_spline_11    25470 non-null  float64\n",
      " 64  Day of month_spline_12    25470 non-null  float64\n",
      " 65  Day of month_spline_13    25470 non-null  float64\n",
      " 66  Day of month_spline_14    25470 non-null  float64\n",
      " 67  Day of month_spline_15    25470 non-null  float64\n",
      " 68  Day of month_spline_16    25470 non-null  float64\n",
      " 69  Day of month_spline_17    25470 non-null  float64\n",
      " 70  Day of month_spline_18    25470 non-null  float64\n",
      " 71  Day of month_spline_19    25470 non-null  float64\n",
      " 72  Day of month_spline_20    25470 non-null  float64\n",
      " 73  Day of month_spline_21    25470 non-null  float64\n",
      " 74  Day of month_spline_22    25470 non-null  float64\n",
      " 75  Day of month_spline_23    25470 non-null  float64\n",
      " 76  Day of month_spline_24    25470 non-null  float64\n",
      " 77  Day of month_spline_25    25470 non-null  float64\n",
      " 78  Day of month_spline_26    25470 non-null  float64\n",
      " 79  Day of month_spline_27    25470 non-null  float64\n",
      " 80  Day of month_spline_28    25470 non-null  float64\n",
      " 81  Day of month_spline_29    25470 non-null  float64\n",
      " 82  Day of month_spline_30    25470 non-null  float64\n",
      " 83  Working_hours             25470 non-null  bool   \n",
      " 84  Total_aob_energy          25470 non-null  float64\n",
      "dtypes: bool(3), float64(82)\n",
      "memory usage: 16.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "import mifs\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare/uncommon values (assuming they are below a threshold or beyond a threshold)\n",
    "df = df[(df['Total_aob_energy'] > df['Total_aob_energy'].quantile(0.01)) & \n",
    "        (df['Total_aob_energy'] < df['Total_aob_energy'].quantile(0.99))]\n",
    "\n",
    "# Define the date ranges for training and testing\n",
    "train_data = df[((df.index.year == 2021) | (df.index.year == 2022)) | \n",
    "                       ((df.index.year == 2023) & (df.index.day <= 14))]\n",
    "test_data = df[(df.index.year == 2023) & (df.index.day > 14)]\n",
    "\n",
    "# Split data into features and target\n",
    "X_train = train_data.drop(['Total_aob_energy'], axis=1)\n",
    "y_train = train_data['Total_aob_energy']\n",
    "X_test = test_data.drop(['Total_aob_energy'], axis=1)\n",
    "y_test = test_data['Total_aob_energy']\n",
    "\n",
    "# # Train and evaluate the model for Split 1\n",
    "# model_split1 = LinearRegression()\n",
    "# model_split1.fit(X_train_split1, y_train_split1)\n",
    "# y_pred_split1 = model_split1.predict(X_test_split1)\n",
    "# rmse_split1 = mean_squared_error(y_test_split1, y_pred_split1, squared=False)\n",
    "# print(f\"Split 1 RMSE: {rmse_split1}\")\n",
    "\n",
    "# # Verify the date ranges\n",
    "# print(\"Split 1 - Train set:\", X_train_split1.index.min(), \"to\", X_train_split1.index.max())\n",
    "# print(\"Split 1 - Test set:\", X_test_split1.index.min(), \"to\", X_test_split1.index.max())\n",
    "# Split the data into training and testing sets using time series split\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "# tscv = TimeSeriesSplit(n_splits=2)\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "# print(X_test, y_test)\n",
    "# X_train = train_data.drop(['Total_aob_energy'], axis=1)\n",
    "# y_train = train_data['Total_aob_energy']\n",
    "# X_test = test_data.drop(['Total_aob_energy'], axis=1)\n",
    "# y_test = test_data['Total_aob_energy']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True  True  True False False  True  True\n",
      "  True False  True  True  True  True False False  True  True  True  True\n",
      " False  True  True  True False  True  True  True  True  True False False\n",
      " False False False False  True  True  True  True  True  True False  True\n",
      "  True  True False False  True False False  True False  True False  True\n",
      "  True  True  True  True  True  True  True  True False  True False False\n",
      "  True  True  True False False  True  True False  True  True False  True]\n",
      "[ True False  True  True  True False  True False  True False  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature Selection with Lasso\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "lasso_features = (lasso.coef_ != 0)\n",
    "print(lasso_features)\n",
    "\n",
    "# Feature Selection with Random Forest and Boruta\n",
    "rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', random_state=42)\n",
    "boruta_selector.fit(X_train_scaled, y_train)\n",
    "boruta_features = boruta_selector.support_\n",
    "print(boruta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False  True  True False  True  True  True  True  True  True\n",
      "  True False False False False False False False False False False  True\n",
      " False  True  True False False  True  True False False False False False\n",
      " False False  True False False  True False False  True  True False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature Selection with SHAP and RandomForest\n",
    "rf_shap = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_shap.fit(X_test_scaled, y_test)\n",
    "explainer = shap.TreeExplainer(rf_shap)\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "shap_features = shap_sum > np.percentile(shap_sum, 75)  # Top 25% SHAP values\n",
    "print(shap_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by SVR (Top 25%): [ True False  True  True  True False  True False False  True  True  True\n",
      "  True False  True  True  True False  True False  True  True False False\n",
      " False False False False  True  True False  True False False False False\n",
      " False False False False False False False False  True  True False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Fit an SVR model\n",
    "svr = SVR(kernel='linear')\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract feature importance based on the coefficients\n",
    "svr_features = np.abs(svr.coef_[0]) > np.percentile(np.abs(svr.coef_[0]), 75)  # Top 25% features\n",
    "print(\"Features selected by SVR (Top 25%):\", svr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Lasso\": Lasso(),\n",
    "        \"Random Forest\": RandomForestRegressor(),\n",
    "        \"SVR\": SVR(),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        results[name] = rmse\n",
    "        print(f\"{name} RMSE: {rmse}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Feature Selection:\n",
      "Index(['Weekend', 'Year', 'Temperature', 'Feelslike', 'Windspeed',\n",
      "       'Month_spline_1', 'Month_spline_2', 'Month_spline_3', 'Hour_spline_8',\n",
      "       'Hour_spline_9', 'Hour_spline_23', 'Day of week_spline_0',\n",
      "       'Working_hours'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def combine_feature_importances(X_columns, lasso_features, boruta_features, shap_features, svr_features, weights=None):\n",
    "    if weights is None:\n",
    "        weights = {'lasso': 1, 'boruta': 1, 'shap': 1, 'svr': 1}\n",
    "    \n",
    "    # Initialize scores array\n",
    "    feature_scores = np.zeros(len(X_columns))\n",
    "\n",
    "    # Assign scores based on feature selection outcomes\n",
    "    feature_scores += weights['lasso'] * lasso_features\n",
    "    feature_scores += weights['boruta'] * boruta_features\n",
    "    feature_scores += weights['shap'] * shap_features\n",
    "    feature_scores += weights['svr'] * svr_features\n",
    "\n",
    "    # Normalize scores\n",
    "    max_score = np.max(feature_scores)\n",
    "    if max_score > 0:\n",
    "        feature_scores /= max_score\n",
    "    \n",
    "    # Decide on a threshold to select features\n",
    "    selected_features = feature_scores > 0.5  # Select features with a score above 0.5\n",
    "   \n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Combine feature importances\n",
    "combined_features = combine_feature_importances(\n",
    "    X_columns=X_train.columns, \n",
    "    lasso_features=lasso_features,\n",
    "    boruta_features=boruta_features,\n",
    "    shap_features=shap_features,\n",
    "    svr_features=svr_features\n",
    "    #weights={'lasso': 1, 'boruta': 1.5, 'shap': 1.5, 'svr': 1}\n",
    ")\n",
    "\n",
    "print(\"Combined Feature Selection:\")\n",
    "print(X_train.columns[combined_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Coefficient of Variation of Root Mean Square Error (CV(RMSE))\n",
    "    :param y_true: array-like of true values\n",
    "    :param y_pred: array-like of predicted values\n",
    "    :return: CV(RMSE) value\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    mean_y_true = np.mean(y_true)\n",
    "    cv_rmse_value = rmse / mean_y_true\n",
    "    return cv_rmse_value\n",
    "\n",
    "def md_mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Median Absolute Percentage Error (MD(MAPE))\n",
    "    :param y_true: array-like of true values\n",
    "    :param y_pred: array-like of predicted values\n",
    "    :return: MD(MAPE) value\n",
    "    \"\"\"\n",
    "    ape = np.abs((y_true - y_pred) / y_true) * 100\n",
    "    md_mape_value = np.median(ape)\n",
    "    return md_mape_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  Train RMSE: 0.9452, Test RMSE: 0.8786\n",
      "  Train MAE: 0.6953, Test MAE: 0.6255\n",
      "  Train SMAPE: 37.23%, Test SMAPE: 29.11%\n",
      "  Train R^2: 0.4344, Test R^2: 0.4329\n",
      "  Test NRMSE: 0.4242\n",
      "  Train CV RMSE: 0.5077, Test CV RMSE: 0.4242\n",
      "  Train Median Mape: 32.7478, Test Median Mape: 24.6476\n",
      "Random Forest:\n",
      "  Train RMSE: 0.4511, Test RMSE: 0.8888\n",
      "  Train MAE: 0.2882, Test MAE: 0.6040\n",
      "  Train SMAPE: 15.67%, Test SMAPE: 26.90%\n",
      "  Train R^2: 0.8712, Test R^2: 0.4196\n",
      "  Test NRMSE: 0.4291\n",
      "  Train CV RMSE: 0.2423, Test CV RMSE: 0.4291\n",
      "  Train Median Mape: 11.5821, Test Median Mape: 20.8675\n",
      "Gradient Boosting:\n",
      "  Train RMSE: 0.8222, Test RMSE: 0.8152\n",
      "  Train MAE: 0.5675, Test MAE: 0.5625\n",
      "  Train SMAPE: 28.96%, Test SMAPE: 25.46%\n",
      "  Train R^2: 0.5720, Test R^2: 0.5117\n",
      "  Test NRMSE: 0.3936\n",
      "  Train CV RMSE: 0.4417, Test CV RMSE: 0.3936\n",
      "  Train Median Mape: 23.6837, Test Median Mape: 19.9886\n",
      "Ridge:\n",
      "  Train RMSE: 0.9452, Test RMSE: 0.8786\n",
      "  Train MAE: 0.6953, Test MAE: 0.6255\n",
      "  Train SMAPE: 37.23%, Test SMAPE: 29.11%\n",
      "  Train R^2: 0.4344, Test R^2: 0.4329\n",
      "  Test NRMSE: 0.4241\n",
      "  Train CV RMSE: 0.5077, Test CV RMSE: 0.4241\n",
      "  Train Median Mape: 32.7602, Test Median Mape: 24.6523\n",
      "Lasso:\n",
      "  Train RMSE: 1.2568, Test RMSE: 1.1854\n",
      "  Train MAE: 0.9872, Test MAE: 0.8610\n",
      "  Train SMAPE: 51.41%, Test SMAPE: 40.07%\n",
      "  Train R^2: 0.0000, Test R^2: -0.0324\n",
      "  Test NRMSE: 0.5723\n",
      "  Train CV RMSE: 0.6751, Test CV RMSE: 0.5723\n",
      "  Train Median Mape: 56.1304, Test Median Mape: 44.3638\n",
      "SVR:\n",
      "  Train RMSE: 0.7915, Test RMSE: 0.8529\n",
      "  Train MAE: 0.5078, Test MAE: 0.5632\n",
      "  Train SMAPE: 25.57%, Test SMAPE: 25.14%\n",
      "  Train R^2: 0.6034, Test R^2: 0.4655\n",
      "  Test NRMSE: 0.4118\n",
      "  Train CV RMSE: 0.4252, Test CV RMSE: 0.4118\n",
      "  Train Median Mape: 18.7714, Test Median Mape: 19.0671\n"
     ]
    }
   ],
   "source": [
    "# Filter training and testing sets with combined features\n",
    "X_train_selected = X_train.loc[:, combined_features]\n",
    "X_test_selected = X_test.loc[:, combined_features]\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-10))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Training Errors\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_smape = smape(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_cv_rmse = cv_rmse(y_train, y_train_pred)\n",
    "    train_mdmape = md_mape(y_train, y_train_pred)\n",
    "\n",
    "    # Testing Errors\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_smape = smape(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_cv_rmse = cv_rmse(y_test, y_test_pred)\n",
    "    test_mdmape = md_mape(y_test, y_test_pred)\n",
    "\n",
    "    # Normalized RMSE\n",
    "    y_mean = np.mean(y_test)\n",
    "    test_nrmse = test_rmse / y_mean\n",
    "\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Train MAE: {train_mae:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    print(f\"  Train SMAPE: {train_smape:.2f}%, Test SMAPE: {test_smape:.2f}%\")\n",
    "    print(f\"  Train R^2: {train_r2:.4f}, Test R^2: {test_r2:.4f}\")\n",
    "    print(f\"  Test NRMSE: {test_nrmse:.4f}\")\n",
    "    print(f\"  Train CV RMSE: {train_cv_rmse:.4f}, Test CV RMSE: {test_cv_rmse:.4f}\")\n",
    "    print(f\"  Train Median Mape: {train_mdmape:.4f}, Test Median Mape: {test_mdmape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  Train RMSE: 0.9428, Test RMSE: 0.9005\n",
      "  Train MAE: 0.7007, Test MAE: 0.6368\n",
      "  Train SMAPE: 38.16%, Test SMAPE: 31.56%\n",
      "  Train R^2: 0.4372, Test R^2: 0.4042\n",
      "  Test NRMSE: 0.4347\n",
      "  Train CV RMSE: 0.5065, Test CV RMSE: 0.4347\n",
      "  Train Median Mape: 33.4636, Test Median Mape: 25.6347\n",
      "Random Forest:\n",
      "  Train RMSE: 0.2956, Test RMSE: 0.8954\n",
      "  Train MAE: 0.1946, Test MAE: 0.5985\n",
      "  Train SMAPE: 10.83%, Test SMAPE: 27.65%\n",
      "  Train R^2: 0.9447, Test R^2: 0.4110\n",
      "  Test NRMSE: 0.4322\n",
      "  Train CV RMSE: 0.1588, Test CV RMSE: 0.4322\n",
      "  Train Median Mape: 8.0973, Test Median Mape: 20.1879\n",
      "Gradient Boosting:\n",
      "  Train RMSE: 0.8147, Test RMSE: 0.8567\n",
      "  Train MAE: 0.5704, Test MAE: 0.5764\n",
      "  Train SMAPE: 29.55%, Test SMAPE: 26.80%\n",
      "  Train R^2: 0.5798, Test R^2: 0.4607\n",
      "  Test NRMSE: 0.4136\n",
      "  Train CV RMSE: 0.4376, Test CV RMSE: 0.4136\n",
      "  Train Median Mape: 24.3902, Test Median Mape: 19.6538\n",
      "Ridge:\n",
      "  Train RMSE: 0.9428, Test RMSE: 0.9005\n",
      "  Train MAE: 0.7007, Test MAE: 0.6367\n",
      "  Train SMAPE: 38.16%, Test SMAPE: 31.56%\n",
      "  Train R^2: 0.4372, Test R^2: 0.4042\n",
      "  Test NRMSE: 0.4347\n",
      "  Train CV RMSE: 0.5065, Test CV RMSE: 0.4347\n",
      "  Train Median Mape: 33.4441, Test Median Mape: 25.6239\n",
      "Lasso:\n",
      "  Train RMSE: 1.2568, Test RMSE: 1.1854\n",
      "  Train MAE: 0.9872, Test MAE: 0.8610\n",
      "  Train SMAPE: 51.41%, Test SMAPE: 40.07%\n",
      "  Train R^2: 0.0000, Test R^2: -0.0324\n",
      "  Test NRMSE: 0.5723\n",
      "  Train CV RMSE: 0.6751, Test CV RMSE: 0.5723\n",
      "  Train Median Mape: 56.1304, Test Median Mape: 44.3638\n",
      "SVR:\n",
      "  Train RMSE: 0.7955, Test RMSE: 0.8863\n",
      "  Train MAE: 0.5216, Test MAE: 0.6005\n",
      "  Train SMAPE: 26.73%, Test SMAPE: 28.98%\n",
      "  Train R^2: 0.5993, Test R^2: 0.4228\n",
      "  Test NRMSE: 0.4279\n",
      "  Train CV RMSE: 0.4273, Test CV RMSE: 0.4279\n",
      "  Train Median Mape: 20.5027, Test Median Mape: 20.5309\n"
     ]
    }
   ],
   "source": [
    "# Filter training and testing sets with combined features\n",
    "X_train_selected = X_train.loc[:, shap_features]\n",
    "X_test_selected = X_test.loc[:, shap_features]\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-10))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Training Errors\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_smape = smape(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_cv_rmse = cv_rmse(y_train, y_train_pred)\n",
    "    train_mdmape = md_mape(y_train, y_train_pred)\n",
    "\n",
    "    # Testing Errors\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_smape = smape(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_cv_rmse = cv_rmse(y_test, y_test_pred)\n",
    "    test_mdmape = md_mape(y_test, y_test_pred)\n",
    "\n",
    "    # Normalized RMSE\n",
    "    y_mean = np.mean(y_test)\n",
    "    test_nrmse = test_rmse / y_mean\n",
    "\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Train MAE: {train_mae:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    print(f\"  Train SMAPE: {train_smape:.2f}%, Test SMAPE: {test_smape:.2f}%\")\n",
    "    print(f\"  Train R^2: {train_r2:.4f}, Test R^2: {test_r2:.4f}\")\n",
    "    print(f\"  Test NRMSE: {test_nrmse:.4f}\")\n",
    "    print(f\"  Train CV RMSE: {train_cv_rmse:.4f}, Test CV RMSE: {test_cv_rmse:.4f}\")\n",
    "    print(f\"  Train Median Mape: {train_mdmape:.4f}, Test Median Mape: {test_mdmape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  Train RMSE: 0.9150, Test RMSE: 0.8871\n",
      "  Train MAE: 0.6801, Test MAE: 0.6365\n",
      "  Train SMAPE: 37.60%, Test SMAPE: 31.84%\n",
      "  Train R^2: 0.4699, Test R^2: 0.4218\n",
      "  Test NRMSE: 0.4283\n",
      "  Train CV RMSE: 0.4915, Test CV RMSE: 0.4283\n",
      "  Train Median Mape: 32.4320, Test Median Mape: 26.0735\n",
      "Random Forest:\n",
      "  Train RMSE: 0.2490, Test RMSE: 0.8079\n",
      "  Train MAE: 0.1627, Test MAE: 0.5477\n",
      "  Train SMAPE: 9.03%, Test SMAPE: 24.58%\n",
      "  Train R^2: 0.9607, Test R^2: 0.5204\n",
      "  Test NRMSE: 0.3900\n",
      "  Train CV RMSE: 0.1338, Test CV RMSE: 0.3900\n",
      "  Train Median Mape: 6.8936, Test Median Mape: 19.6749\n",
      "Gradient Boosting:\n",
      "  Train RMSE: 0.7802, Test RMSE: 0.7958\n",
      "  Train MAE: 0.5432, Test MAE: 0.5476\n",
      "  Train SMAPE: 28.03%, Test SMAPE: 24.84%\n",
      "  Train R^2: 0.6146, Test R^2: 0.5347\n",
      "  Test NRMSE: 0.3842\n",
      "  Train CV RMSE: 0.4191, Test CV RMSE: 0.3842\n",
      "  Train Median Mape: 23.2679, Test Median Mape: 20.6124\n",
      "Ridge:\n",
      "  Train RMSE: 0.9150, Test RMSE: 0.8871\n",
      "  Train MAE: 0.6800, Test MAE: 0.6365\n",
      "  Train SMAPE: 37.60%, Test SMAPE: 31.84%\n",
      "  Train R^2: 0.4699, Test R^2: 0.4218\n",
      "  Test NRMSE: 0.4283\n",
      "  Train CV RMSE: 0.4915, Test CV RMSE: 0.4283\n",
      "  Train Median Mape: 32.4324, Test Median Mape: 26.0790\n",
      "Lasso:\n",
      "  Train RMSE: 1.2568, Test RMSE: 1.1854\n",
      "  Train MAE: 0.9872, Test MAE: 0.8610\n",
      "  Train SMAPE: 51.41%, Test SMAPE: 40.07%\n",
      "  Train R^2: 0.0000, Test R^2: -0.0324\n",
      "  Test NRMSE: 0.5723\n",
      "  Train CV RMSE: 0.6751, Test CV RMSE: 0.5723\n",
      "  Train Median Mape: 56.1304, Test Median Mape: 44.3638\n",
      "SVR:\n",
      "  Train RMSE: 0.6769, Test RMSE: 0.9204\n",
      "  Train MAE: 0.4181, Test MAE: 0.6206\n",
      "  Train SMAPE: 20.97%, Test SMAPE: 28.86%\n",
      "  Train R^2: 0.7099, Test R^2: 0.3775\n",
      "  Test NRMSE: 0.4444\n",
      "  Train CV RMSE: 0.3636, Test CV RMSE: 0.4444\n",
      "  Train Median Mape: 13.3747, Test Median Mape: 23.0657\n"
     ]
    }
   ],
   "source": [
    "# Filter training and testing sets with combined features\n",
    "X_train_selected = X_train.loc[:, lasso_features]\n",
    "X_test_selected = X_test.loc[:, lasso_features]\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-10))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Training Errors\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_smape = smape(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_cv_rmse = cv_rmse(y_train, y_train_pred)\n",
    "    train_mdmape = md_mape(y_train, y_train_pred)\n",
    "\n",
    "    # Testing Errors\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_smape = smape(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_cv_rmse = cv_rmse(y_test, y_test_pred)\n",
    "    test_mdmape = md_mape(y_test, y_test_pred)\n",
    "\n",
    "    # Normalized RMSE\n",
    "    y_mean = np.mean(y_test)\n",
    "    test_nrmse = test_rmse / y_mean\n",
    "\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Train MAE: {train_mae:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    print(f\"  Train SMAPE: {train_smape:.2f}%, Test SMAPE: {test_smape:.2f}%\")\n",
    "    print(f\"  Train R^2: {train_r2:.4f}, Test R^2: {test_r2:.4f}\")\n",
    "    print(f\"  Test NRMSE: {test_nrmse:.4f}\")\n",
    "    print(f\"  Train CV RMSE: {train_cv_rmse:.4f}, Test CV RMSE: {test_cv_rmse:.4f}\")\n",
    "    print(f\"  Train Median Mape: {train_mdmape:.4f}, Test Median Mape: {test_mdmape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  Train RMSE: 0.9634, Test RMSE: 0.9075\n",
      "  Train MAE: 0.7128, Test MAE: 0.6386\n",
      "  Train SMAPE: 38.17%, Test SMAPE: 29.39%\n",
      "  Train R^2: 0.4124, Test R^2: 0.3950\n",
      "  Test NRMSE: 0.4381\n",
      "  Train CV RMSE: 0.5175, Test CV RMSE: 0.4381\n",
      "  Train Median Mape: 34.0598, Test Median Mape: 24.4586\n",
      "Random Forest:\n",
      "  Train RMSE: 0.3695, Test RMSE: 0.8940\n",
      "  Train MAE: 0.2377, Test MAE: 0.6096\n",
      "  Train SMAPE: 13.04%, Test SMAPE: 27.15%\n",
      "  Train R^2: 0.9135, Test R^2: 0.4128\n",
      "  Test NRMSE: 0.4316\n",
      "  Train CV RMSE: 0.1985, Test CV RMSE: 0.4316\n",
      "  Train Median Mape: 9.6545, Test Median Mape: 21.0751\n",
      "Gradient Boosting:\n",
      "  Train RMSE: 0.8396, Test RMSE: 0.8425\n",
      "  Train MAE: 0.5820, Test MAE: 0.5800\n",
      "  Train SMAPE: 29.62%, Test SMAPE: 26.20%\n",
      "  Train R^2: 0.5537, Test R^2: 0.4785\n",
      "  Test NRMSE: 0.4067\n",
      "  Train CV RMSE: 0.4510, Test CV RMSE: 0.4067\n",
      "  Train Median Mape: 23.8728, Test Median Mape: 20.9511\n",
      "Ridge:\n",
      "  Train RMSE: 0.9634, Test RMSE: 0.9075\n",
      "  Train MAE: 0.7128, Test MAE: 0.6386\n",
      "  Train SMAPE: 38.17%, Test SMAPE: 29.39%\n",
      "  Train R^2: 0.4124, Test R^2: 0.3950\n",
      "  Test NRMSE: 0.4381\n",
      "  Train CV RMSE: 0.5175, Test CV RMSE: 0.4381\n",
      "  Train Median Mape: 34.0443, Test Median Mape: 24.4432\n",
      "Lasso:\n",
      "  Train RMSE: 1.2568, Test RMSE: 1.1854\n",
      "  Train MAE: 0.9872, Test MAE: 0.8610\n",
      "  Train SMAPE: 51.41%, Test SMAPE: 40.07%\n",
      "  Train R^2: 0.0000, Test R^2: -0.0324\n",
      "  Test NRMSE: 0.5723\n",
      "  Train CV RMSE: 0.6751, Test CV RMSE: 0.5723\n",
      "  Train Median Mape: 56.1304, Test Median Mape: 44.3638\n",
      "SVR:\n",
      "  Train RMSE: 0.8114, Test RMSE: 0.8768\n",
      "  Train MAE: 0.5193, Test MAE: 0.5748\n",
      "  Train SMAPE: 26.11%, Test SMAPE: 25.56%\n",
      "  Train R^2: 0.5831, Test R^2: 0.4352\n",
      "  Test NRMSE: 0.4233\n",
      "  Train CV RMSE: 0.4359, Test CV RMSE: 0.4233\n",
      "  Train Median Mape: 19.5553, Test Median Mape: 19.5583\n"
     ]
    }
   ],
   "source": [
    "# Filter training and testing sets with combined features\n",
    "X_train_selected = X_train.loc[:, boruta_features]\n",
    "X_test_selected = X_test.loc[:, boruta_features]\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-10))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Training Errors\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_smape = smape(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_cv_rmse = cv_rmse(y_train, y_train_pred)\n",
    "    train_mdmape = md_mape(y_train, y_train_pred)\n",
    "\n",
    "    # Testing Errors\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_smape = smape(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_cv_rmse = cv_rmse(y_test, y_test_pred)\n",
    "    test_mdmape = md_mape(y_test, y_test_pred)\n",
    "\n",
    "    # Normalized RMSE\n",
    "    y_mean = np.mean(y_test)\n",
    "    test_nrmse = test_rmse / y_mean\n",
    "\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Train MAE: {train_mae:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    print(f\"  Train SMAPE: {train_smape:.2f}%, Test SMAPE: {test_smape:.2f}%\")\n",
    "    print(f\"  Train R^2: {train_r2:.4f}, Test R^2: {test_r2:.4f}\")\n",
    "    print(f\"  Test NRMSE: {test_nrmse:.4f}\")\n",
    "    print(f\"  Train CV RMSE: {train_cv_rmse:.4f}, Test CV RMSE: {test_cv_rmse:.4f}\")\n",
    "    print(f\"  Train Median Mape: {train_mdmape:.4f}, Test Median Mape: {test_mdmape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  Train RMSE: 0.9421, Test RMSE: 0.8894\n",
      "  Train MAE: 0.6933, Test MAE: 0.6371\n",
      "  Train SMAPE: 37.13%, Test SMAPE: 29.84%\n",
      "  Train R^2: 0.4381, Test R^2: 0.4189\n",
      "  Test NRMSE: 0.4294\n",
      "  Train CV RMSE: 0.5061, Test CV RMSE: 0.4294\n",
      "  Train Median Mape: 32.6684, Test Median Mape: 25.1301\n",
      "Random Forest:\n",
      "  Train RMSE: 0.3979, Test RMSE: 0.9065\n",
      "  Train MAE: 0.2473, Test MAE: 0.6264\n",
      "  Train SMAPE: 13.40%, Test SMAPE: 28.05%\n",
      "  Train R^2: 0.8997, Test R^2: 0.3963\n",
      "  Test NRMSE: 0.4376\n",
      "  Train CV RMSE: 0.2138, Test CV RMSE: 0.4376\n",
      "  Train Median Mape: 9.4323, Test Median Mape: 22.0308\n",
      "Gradient Boosting:\n",
      "  Train RMSE: 0.8253, Test RMSE: 0.8338\n",
      "  Train MAE: 0.5763, Test MAE: 0.5795\n",
      "  Train SMAPE: 29.65%, Test SMAPE: 26.25%\n",
      "  Train R^2: 0.5687, Test R^2: 0.4892\n",
      "  Test NRMSE: 0.4025\n",
      "  Train CV RMSE: 0.4434, Test CV RMSE: 0.4025\n",
      "  Train Median Mape: 24.8205, Test Median Mape: 21.6146\n",
      "Ridge:\n",
      "  Train RMSE: 0.9421, Test RMSE: 0.8894\n",
      "  Train MAE: 0.6933, Test MAE: 0.6371\n",
      "  Train SMAPE: 37.13%, Test SMAPE: 29.83%\n",
      "  Train R^2: 0.4381, Test R^2: 0.4189\n",
      "  Test NRMSE: 0.4294\n",
      "  Train CV RMSE: 0.5061, Test CV RMSE: 0.4294\n",
      "  Train Median Mape: 32.6653, Test Median Mape: 25.1315\n",
      "Lasso:\n",
      "  Train RMSE: 1.2568, Test RMSE: 1.1854\n",
      "  Train MAE: 0.9872, Test MAE: 0.8610\n",
      "  Train SMAPE: 51.41%, Test SMAPE: 40.07%\n",
      "  Train R^2: 0.0000, Test R^2: -0.0324\n",
      "  Test NRMSE: 0.5723\n",
      "  Train CV RMSE: 0.6751, Test CV RMSE: 0.5723\n",
      "  Train Median Mape: 56.1304, Test Median Mape: 44.3638\n",
      "SVR:\n",
      "  Train RMSE: 0.7989, Test RMSE: 0.8506\n",
      "  Train MAE: 0.5139, Test MAE: 0.5780\n",
      "  Train SMAPE: 25.79%, Test SMAPE: 26.19%\n",
      "  Train R^2: 0.5959, Test R^2: 0.4684\n",
      "  Test NRMSE: 0.4106\n",
      "  Train CV RMSE: 0.4292, Test CV RMSE: 0.4106\n",
      "  Train Median Mape: 18.9602, Test Median Mape: 19.7350\n"
     ]
    }
   ],
   "source": [
    "# Filter training and testing sets with combined features\n",
    "X_train_selected = X_train.loc[:, svr_features]\n",
    "X_test_selected = X_test.loc[:, svr_features]\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"SVR\": SVR()\n",
    "}\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-10))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Training Errors\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_smape = smape(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_cv_rmse = cv_rmse(y_train, y_train_pred)\n",
    "    train_mdmape = md_mape(y_train, y_train_pred)\n",
    "\n",
    "    # Testing Errors\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_smape = smape(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_cv_rmse = cv_rmse(y_test, y_test_pred)\n",
    "    test_mdmape = md_mape(y_test, y_test_pred)\n",
    "\n",
    "    # Normalized RMSE\n",
    "    y_mean = np.mean(y_test)\n",
    "    test_nrmse = test_rmse / y_mean\n",
    "\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Train MAE: {train_mae:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "    print(f\"  Train SMAPE: {train_smape:.2f}%, Test SMAPE: {test_smape:.2f}%\")\n",
    "    print(f\"  Train R^2: {train_r2:.4f}, Test R^2: {test_r2:.4f}\")\n",
    "    print(f\"  Test NRMSE: {test_nrmse:.4f}\")\n",
    "    print(f\"  Train CV RMSE: {train_cv_rmse:.4f}, Test CV RMSE: {test_cv_rmse:.4f}\")\n",
    "    print(f\"  Train Median Mape: {train_mdmape:.4f}, Test Median Mape: {test_mdmape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
